import copy
import sys
import warnings
import numpy as np
import pandas as pd
import streamlit as st
from copy import deepcopy
from data_process import data_process
from load_pred import load_pred
from new_supply_curve import supply_curve
from price_pred import price_pred
from thermal_load import thermal_load

warnings.filterwarnings("ignore")

sys.path.append('..')
from logger import Logger
from utils import get_time_index, str_to_list, merge_lists

# è·å–æ—¥å¿—å¯¹è±¡
logger = Logger.get_logger(True, False)

st.set_page_config(page_title="æ¨¡æ‹Ÿå‡ºæ¸…", page_icon="ğŸŒ", layout="wide")
# å»é™¤é¡µè„š
st.markdown("""<style>footer {visibility: hidden;}</style>""", unsafe_allow_html=True)

df, pl = None, None
if 'æœºç»„æŠ¥ä»·è¡¨' in st.session_state:
    df = st.session_state['æœºç»„æŠ¥ä»·è¡¨']
    if df['æœºç»„åç§°'].isna().all():
        st.error("è¯·åœ¨â€œæ•°æ®å‡†å¤‡â€ä¸­å¤åˆ¶å¥½ã€Šæœºç»„æŠ¥ä»·è¡¨ã€‹ï¼ï¼", icon="ğŸš¨")
else:
    st.error("è¯·åœ¨â€œæ•°æ®å‡†å¤‡â€ä¸­å¤åˆ¶å¥½ã€Šæœºç»„æŠ¥ä»·è¡¨ã€‹ï¼ï¼", icon="ğŸš¨")
if 'æŠ«éœ²è¡¨' in st.session_state:
    pl = st.session_state['æŠ«éœ²è¡¨']
else:
    st.error("è¯·åœ¨â€œæ•°æ®å‡†å¤‡â€ä¸­ä¸Šä¼ ã€Šäº‹å‰ä¿¡æ¯æŠ«éœ²è¡¨ã€‹ï¼ï¼", icon="ğŸš¨")

# è°ƒé¢‘
min_cap = 0.55
max_cap = 0.95
fm_step = 0.05

startup_shutdown = None
stop_unit = None
fm_quotation = None
spinning_reserve = None
if 'å¼€åœæœº' in st.session_state.keys():
    startup_shutdown = st.session_state['å¼€åœæœº']
if 'åœæœºæœºç»„' in st.session_state.keys():
    stop_unit = st.session_state['åœæœºæœºç»„']
if 'è°ƒé¢‘æŠ¥ä»·è¡¨' in st.session_state.keys():
    fm_quotation = st.session_state['è°ƒé¢‘æŠ¥ä»·è¡¨']
    fm_quotation.iloc[:, 1:] = fm_quotation.iloc[:, 1:].astype(float)
if 'æ—‹è½¬å¤‡ç”¨' in st.session_state.keys():
    spinning_reserve = st.session_state['æ—‹è½¬å¤‡ç”¨']

# ç”Ÿæˆ00:15-00:00çš„96ä¸ªç‚¹çš„æ—¶åˆ»
time_list = [f"{hour:02d}:{minute:02d}" for hour in range(0, 24) for minute in range(0, 60, 15) if
             not (hour == 0 and minute < 15)] + ['00:00']
# ç”Ÿæˆ00:15-00:00çš„24ä¸ªç‚¹çš„æ—¶åˆ»
hour_list = ['{:02d}:15'.format(hour) for hour in range(24)]

# é›†å›¢åˆ—è¡¨
group_lists = ["èµ£èƒ½", "åèƒ½", "å›½å®¶èƒ½æº", "å›½å®¶ç”µæŠ•", 'å¤§å”']

# èƒ½å¦å‡ºæ¸…æ ‡è¯†
result_flag = False

# å³°å¹³è°·é…ç½®:
try:
    peak_valley_df = pd.read_csv('config/peak_valley_config.csv', encoding='gbk')
    peak_valley_df = peak_valley_df.astype(str)
    peak_valley_df = peak_valley_df.where(peak_valley_df != 'nan', None)
except Exception:
    peak_valley_df = None

# æœºç»„çˆ¬å¡é€Ÿç‡é…ç½®
try:
    ramp_rate_df = pd.read_csv('config/ramp_rate.csv', encoding='gbk')
    ramp_rate_df = ramp_rate_df.where(ramp_rate_df != 'nan', None)
    ramp_rate_df['çˆ¬å¡é€Ÿç‡ï¼ˆMW/åˆ†é’Ÿï¼‰'] = ramp_rate_df['çˆ¬å¡é€Ÿç‡ï¼ˆMW/åˆ†é’Ÿï¼‰'].apply(lambda x: x * 15)  # æ¯15åˆ†é’Ÿçš„çˆ¬å¡é€Ÿç‡
except Exception:
    ramp_rate_df = None

# æœºç»„å¼€åœæœºæ›²çº¿é…ç½®
try:
    start_stop_curve_df = pd.read_excel('config/start_stop_curve.xlsx')
    start_stop_curve_df = start_stop_curve_df.astype(str)
    start_stop_curve_df = start_stop_curve_df.where(start_stop_curve_df != 'nan', None)
except Exception:
    start_stop_curve_df = None

if df is not None and pl is not None:

    @st.cache_data
    # è·å–å®éªŒæœºç»„å’Œå¼€åœæœºæœºç»„çš„æ—¶åˆ»è¯•éªŒè´Ÿè·å’Œæ—¶åˆ»å…³æœºæœºç»„ï¼ˆæ–°å¢ï¼‰
    def time_shut_exp_unit_and_load(uss_df: pd.DataFrame, ssc_df: pd.DataFrame):
        time_shut_set = [set() for _ in range(96)]  # æ„å»ºåŒ…å«96ä¸ªç©ºsetçš„åˆ—è¡¨
        time_exp_set = [set() for _ in range(96)]  # æ„å»ºåŒ…å«96ä¸ªç©ºsetçš„åˆ—è¡¨
        time_exp_load_list = [0] * 96  # æ„å»ºåŒ…å«96ä¸ª0çš„åˆ—è¡¨
        curve_dict = {'æœºç»„åç§°': [], 'å¼€æœºæ›²çº¿': [], 'åœæœºæ›²çº¿': [], 'åŒºé—´ç´¢å¼•': []}
        if uss_df is not None:
            for _, row in uss_df.iterrows():
                unit_name = row['æœºç»„åç§°']
                start_flag = row['å¼€æœºçŠ¶æ€']
                start_time = row['å¼€æœºæ—¶é—´']
                shut_time = row['åœæœºæ—¶é—´']
                curve_list = []
                index_list = []

                ssc_rows = ssc_df.loc[ssc_df['æœºç»„åç§°'] == unit_name]  # è·å–æœºç»„çš„å¼€åœæœºæ›²çº¿
                if len(ssc_rows) > 0:
                    ssc_row = ssc_rows.iloc[0]
                    stop_load_curve = ssc_row['åœæœºæ›²çº¿']
                    start_load_curve = ssc_row['å¼€æœºæ›²çº¿']
                    stop_load_curve = str_to_list(stop_load_curve, None)
                    start_load_curve = str_to_list(start_load_curve, None)
                else:
                    stop_load_curve = None
                    start_load_curve = None

                if start_flag:  # å¦‚æœæ˜¯å¼€æœºçŠ¶æ€ï¼Œé‚£ä¹ˆåªå…³æ³¨åœæœºæ—¶é—´
                    if shut_time is not pd.NaT:
                        time_index = get_time_index(shut_time)
                        for i in range(time_index + 1, 96):
                            time_shut_set[i].add(unit_name)
                            if stop_load_curve is not None:  # å›ºå®šè´Ÿè·ä¸­åŠ å…¥åœæœºæ›²çº¿çš„è´Ÿè·
                                curve_index = i - time_index - 1
                                if curve_index < len(stop_load_curve):
                                    curve_list.append(stop_load_curve[curve_index])
                                    index_list.append(i)
                        if stop_load_curve is not None:  # æ•°æ®åŠ å…¥åˆ°dictä¸­
                            curve_dict['æœºç»„åç§°'].append(unit_name)
                            curve_dict['å¼€æœºæ›²çº¿'].append([])
                            curve_dict['åœæœºæ›²çº¿'].append(curve_list)
                            curve_dict['åŒºé—´ç´¢å¼•'].append(index_list)
                else:  # å¦‚æœæ˜¯å…³æœºçŠ¶æ€ï¼Œ é‚£ä¹ˆåªå…³æ³¨å¼€æœºæ—¶é—´
                    if start_time is not pd.NaT:
                        time_index = get_time_index(start_time)
                        for i in range(0, time_index + 1):
                            time_shut_set[i].add(unit_name)
                        if start_load_curve is not None:  # å›ºå®šè´Ÿè·ä¸­åŠ å…¥å¼€æœºæ›²çº¿çš„è´Ÿè·
                            for j in range(time_index + 1, 96):
                                curve_index = j - time_index - 1
                                if curve_index < len(start_load_curve):
                                    curve_list.append(start_load_curve[curve_index])
                                    index_list.append(j)
                            curve_dict['æœºç»„åç§°'].append(unit_name)
                            curve_dict['å¼€æœºæ›²çº¿'].append(curve_list)
                            curve_dict['åœæœºæ›²çº¿'].append([])
                            curve_dict['åŒºé—´ç´¢å¼•'].append(index_list)
                    else:  # å¦‚æœæ²¡æœ‰å¼€æœºæ—¶é—´ï¼Œé‚£å°±æ˜¯å…¨å¤©å…³æœº
                        for time_shut_list in time_shut_set:
                            time_shut_list.add(unit_name)

                for i in range(1, 4):  # æ€»å®éªŒæ¬¡æ•°ä¸º3
                    exp_start = row['è¯•éªŒå¼€å§‹æ—¶é—´' + str(i)]
                    exp_end = row['è¯•éªŒç»“æŸæ—¶é—´' + str(i)]
                    exp_loads = row['è¯•éªŒè´Ÿè·' + str(i)]
                    if exp_start is not pd.NaT and exp_end is not pd.NaT and not pd.isna(exp_loads):
                        start_time_index = get_time_index(exp_start)
                        end_time_index = get_time_index(exp_end)
                        load_list = str_to_list(exp_loads, end_time_index - start_time_index)
                        for i in range(start_time_index + 1, end_time_index + 1):  # å®éªŒåŒºé—´çš„æ—¶åˆ»
                            time_exp_set[i].add(unit_name)
                            time_exp_load_list[i] += load_list[i - start_time_index - 1]
        return time_shut_set, time_exp_set, time_exp_load_list, pd.DataFrame(curve_dict)

    # å…³æœºæœºç»„å’Œè¯•éªŒæœºç»„åˆå¹¶å¼€åœæœºçµæ´»æ›²çº¿ï¼Œçˆ¬å¡çº¦æŸè´Ÿè·å’Œå›ºå®šè´Ÿè·åˆå¹¶
    def load_list_combine_flexible_df(tel_list, flex_df, trr_df):
        flexible_time_exp_load_list = deepcopy(tel_list)
        for _, row in flex_df.iterrows():
            index_list = row['åŒºé—´ç´¢å¼•']
            start_curve = row['å¼€æœºæ›²çº¿']
            stop_curve = row['åœæœºæ›²çº¿']
            if len(start_curve) == 0 and len(stop_curve) > 0:  # åœæœº
                for index in index_list:
                    flexible_time_exp_load_list[index] += stop_curve[index - index_list[0]]
            if len(stop_curve) == 0 and len(start_curve) > 0:  # å¼€æœº
                for index in index_list:
                    flexible_time_exp_load_list[index] += start_curve[index - index_list[0]]
        for _, row in trr_df.iterrows():
            index_list = row['index']
            fixed_load_list = row['fixed_load']
            for i in range(len(index_list)):
                flexible_time_exp_load_list[index_list[i]] += fixed_load_list[i]
        return flexible_time_exp_load_list


    def remove_set_combine_ramp_rate(rus, trr_df):
        turn_remove_unit_set = deepcopy(rus)
        if not trr_df.empty:
            for _, row in trr_df.iterrows():
                unit_name = row['unit']
                index_list = row['index']
                for index in index_list:
                    turn_remove_unit_set[index].add(unit_name)
        return turn_remove_unit_set


    def fm_exp_unit(index, unit_name, tse_list):
        tse_start_index = index * 4  # 00:15, 00:30, 00:45, 01:00
        tse_end_index = (index + 1) * 4
        for i in range(tse_start_index, tse_end_index):
            if unit_name in tse_list[i]:
                return True
        return False

    @st.cache_data
    # è·å–æ¯å°æ—¶å‚ä¸è°ƒé¢‘çš„æœºç»„
    def get_hour_fm_unit(fq_df: pd.DataFrame, hour_fm, tse_set):
        if hour_fm is None:
            return [[] for _ in range(24)]
        hour_fm_unit_lists = []
        for index, total_fm_cap in enumerate(hour_fm):  # éå†24å°æ—¶çš„è°ƒé¢‘éœ€æ±‚
            fm_unit_list = []  # å‚ä¸è°ƒé¢‘çš„æœºç»„
            if total_fm_cap == 0:
                hour_fm_unit_lists.append(fm_unit_list)
                continue
            quotation_column = 'è°ƒé¢‘æŠ¥ä»·' + str(index + 1)
            quotation_list = []  # æœ€ç»ˆè°ƒé¢‘æŠ¥ä»·
            param_k_list = []  # è°ƒé¢‘KæŒ‡æ ‡
            unit_capacity_list = []  # æœºç»„å®¹é‡
            unit_name_list = []  # æœºç»„åç§°
            for i, row in fq_df.iterrows():  # éå†è°ƒé¢‘æœºç»„æŠ¥ä»·
                unit_name = row['æœºç»„åç§°']
                if fm_exp_unit(index, unit_name, tse_set):  # å…³æœºè¯•éªŒæœºç»„ä¸èƒ½å‚ä¸è°ƒé¢‘
                    continue
                quotation = float(row[quotation_column])
                all_quotation = float(row['è°ƒé¢‘ç»Ÿä¸€æŠ¥ä»·'])
                param_k = float(row['è°ƒé¢‘æŒ‡æ ‡K'])
                unit_name = row['æœºç»„åç§°']
                if param_k >= 0.9:  # ç³»æ•°ä¸ä½äº0.9
                    if (not pd.isna(all_quotation)) or (not pd.isna(quotation)):  # ç»Ÿä¸€æŠ¥ä»·å’Œæ—¶åˆ»æŠ¥ä»·éƒ½ä¸ä¸ºç©º
                        if not pd.isna(all_quotation):
                            quotation = all_quotation
                        final_quotation = quotation / param_k
                        quotation_list.append(final_quotation)
                        param_k_list.append(param_k)
                        unit_capacity = df.loc[df['æœºç»„åç§°'] == unit_name, 'æœºç»„å®¹é‡(MW)'].iloc[0]  # è·å–æœºç»„å®¹é‡
                        unit_capacity_list.append(float(unit_capacity))
                        unit_name_list.append(unit_name)
            # ä»ä½åˆ°é«˜è¿›è¡Œæ’åºï¼Œç›¸åŒæ—¶çš„å¯¹æ¯”é¡ºåºä¸ºè°ƒé¢‘æŠ¥ä»·ä»ä½åˆ°é«˜ï¼ŒKä»é«˜åˆ°ä½ï¼Œå®¹é‡ä»é«˜åˆ°ä½
            indices = list(range(len(quotation_list)))
            sorted_indices = sorted(indices,
                                    key=lambda i: (quotation_list[i], -param_k_list[i], -unit_capacity_list[i]))
            # ç¡®å®šè°ƒé¢‘å‡ºæ¸…æœºç»„
            fm_cap = 0
            if total_fm_cap is not None:
                for idx in sorted_indices:
                    unit_name = unit_name_list[idx]
                    unit_cap = unit_capacity_list[idx] * fm_step
                    fm_cap += unit_cap
                    fm_unit_list.append(unit_name)
                    if fm_cap >= total_fm_cap:
                        break
            hour_fm_unit_lists.append(fm_unit_list)
        return hour_fm_unit_lists

    # è®¡ç®—ä¸åŒä¾›ç»™æ›²çº¿çš„åˆ†æ®µåŒºé—´
    def get_diff_sc_period(ru_set):
        period = []  # è¿”å›è¿ç»­çš„æ•°å­—åŒºé—´å­—ç¬¦ä¸²åˆ—è¡¨
        start_unit_flag = ru_set[0]  # æ ‡è¯†é˜¶æ®µèµ·å§‹çš„æœºç»„setï¼Œåˆå§‹åŒ–ä¸ºç¬¬ä¸€ä¸ª
        start_flag = 0  # é˜¶æ®µèµ·å§‹çš„æ—¶é—´ï¼Œ åˆå§‹åŒ–ä¸ºç¬¬ä¸€ä¸ª
        for index, unit_set in enumerate(ru_set):
            if unit_set != start_unit_flag:  # å¦‚æœå½“å‰æ—¶åˆ»çš„æœºç»„ä¸ç­‰äºä¸Šä¸€é˜¶æ®µ
                time_unit_map = {}
                time_period = str(start_flag) + '-' + str(index - 1)
                time_unit_map[time_period] = ru_set[index - 1]
                period.append(time_unit_map)
                start_unit_flag = unit_set
                start_flag = index
            if index == len(ru_set) - 1:  # éå†åˆ°æœ€å
                time_unit_map = {}
                time_period = str(start_flag) + '-' + str(index)
                time_unit_map[time_period] = unit_set
                period.append(time_unit_map)
        return period

    def get_exp_load_from_index(uss_df, unit_name, idx):
        row = uss_df[uss_df['æœºç»„åç§°'] == unit_name].iloc[0]
        for i in range(1, 4):
            exp_start = row['è¯•éªŒå¼€å§‹æ—¶é—´' + str(i)]
            exp_end = row['è¯•éªŒç»“æŸæ—¶é—´' + str(i)]
            exp_load = row['è¯•éªŒè´Ÿè·' + str(i)]
            if exp_start is not pd.NaT and exp_end is not pd.NaT and exp_load is not None:
                start_time_index = get_time_index(exp_start) + 1
                end_time_index = get_time_index(exp_end)
                if start_time_index <= idx <= end_time_index:
                    load_list = str_to_list(exp_load, end_time_index - start_time_index + 1)
                    return load_list[idx - start_time_index]

    def get_unit_cap(q_df, unit_name):
        row = q_df[q_df['æœºç»„åç§°'] == unit_name].iloc[0]
        return row['æœºç»„å®¹é‡(MW)']

    def get_unit_sr(sr_df, unit_name):
        try:
            row = sr_df[sr_df['æœºç»„åç§°'] == unit_name].iloc[0]
            return float(row['æ—‹å¤‡å®¹é‡(MW)'])
        except Exception:
            return 0

    def get_unit_ramp_rate(rr_df, unit_name):
        try:
            row = rr_df[rr_df['æœºç»„åç§°'] == unit_name].iloc[0]
            return float(row['çˆ¬å¡é€Ÿç‡ï¼ˆMW/åˆ†é’Ÿï¼‰'])
        except Exception:
            return None

    # æœºç»„å‡ºåŠ›å€¼è°ƒæ•´ï¼ˆæ–°å¢ï¼‰
    def result_unit_load_df_process(rul_df, uss_df, q_df, sr_df, flex_df, ts_set, te_set, minflu_set, maxflu_set, slu_set, trr_df):
        for idx, unit_set in enumerate(ts_set):  # åœæœºæœºç»„
            if len(unit_set) != 0:
                for unit_name in unit_set:
                    rul_df.at[idx, unit_name] = 0
        for _, row in flex_df.iterrows():  # å¼€åœæœºæ›²çº¿é™åˆ¶æœºç»„
            unit_name = row['æœºç»„åç§°']
            index_list = row['åŒºé—´ç´¢å¼•']
            start_curve = row['å¼€æœºæ›²çº¿']
            stop_curve = row['åœæœºæ›²çº¿']
            if len(start_curve) == 0 and len(stop_curve) > 0:  # åœæœº
                for i in range(len(stop_curve)):
                    rul_df.at[index_list[i], unit_name] = stop_curve[i]
            if len(stop_curve) == 0 and len(start_curve) > 0:  # å¼€æœº
                for i in range(len(start_curve)):
                    rul_df.at[index_list[i], unit_name] = start_curve[i]
        for idx, unit_set in enumerate(te_set):  # è¯•éªŒæœºç»„
            if len(unit_set) != 0:
                for unit_name in unit_set:
                    rul_df.at[idx, unit_name] = get_exp_load_from_index(uss_df, unit_name, idx)
        for idx, unit_set in enumerate(minflu_set):  # é™åˆ¶æœ€å°å‡ºåŠ›æœºç»„
            if len(unit_set) != 0:
                for unit_name in unit_set:
                    rul_df.at[idx, unit_name] = get_unit_cap(q_df, unit_name) * min_cap
        for idx, unit_set in enumerate(maxflu_set):  # é™åˆ¶æœ€å¤§å‡ºåŠ›æœºç»„
            if len(unit_set) != 0:
                for unit_name in unit_set:
                    rul_df.at[idx, unit_name] = get_unit_cap(q_df, unit_name) * max_cap
        for idx, unit_set in enumerate(slu_set):  # æ—‹å¤‡é™åˆ¶æœ€å¤§å‡ºåŠ›æœºç»„
            if len(unit_set) != 0:
                for unit_name in unit_set:
                    if pd.isna(rul_df.at[idx, unit_name]):
                        rul_df.at[idx, unit_name] = get_unit_cap(q_df, unit_name) - get_unit_sr(sr_df, unit_name)
                    else:
                        rul_df.at[idx, unit_name] = rul_df.at[idx, unit_name] - get_unit_sr(sr_df, unit_name)
        if not trr_df.empty:  # çˆ¬å¡çº¦æŸæœºç»„
            for _, row in trr_df.iterrows():
                unit_name = row['unit']
                index = row['index']
                fixed_load_list = row['fixed_load']
                for i in range(len(index)):
                    rul_df.at[index[i], unit_name] = fixed_load_list[i]
        # å¦‚æœä¸€å¤©å…¨ä¸º0ï¼Œé‚£ä¹ˆå»é™¤è¯¥æœºç»„
        for column in rul_df.columns:
            if (rul_df[column] == 0).all():
                rul_df = rul_df.drop(column, axis=1)
        return rul_df

    # çˆ¬å¡è¾¹ç•Œæ¡ä»¶é™åˆ¶ï¼ˆä¼˜å…ˆæ»¡è¶³ï¼‰
    def ramp_rate_boundary(rul_df: pd.DataFrame, rr_df: pd.DataFrame, flex_df):
        new_turn_ramp_rate_df = pd.DataFrame(columns=['unit', 'index', 'fixed_load'])
        unit_load_dict = rul_df.to_dict(orient='list')  # è½¬dict
        for key, value in unit_load_dict.items():  # éå†æœºç»„
            ramp_rate = get_unit_ramp_rate(rr_df, key)
            rows = flex_df[flex_df['æœºç»„åç§°'] == key]
            start_index = None
            # åˆ¤æ–­åœæœºèµ·å§‹index
            if len(rows) > 0:
                row = rows.iloc[0]
                if len(row['åœæœºæ›²çº¿']) > 0:
                    index_list = row['åŒºé—´ç´¢å¼•']
                    start_index = index_list[0]
            if not pd.isna(ramp_rate):  # æœºç»„å­˜åœ¨çˆ¬å¡çº¦æŸ
                for i in range(len(value) - 1):  # åˆ¤æ–­å‰åä¸¤ä¸ªå€¼ä¹‹é—´çš„å·®å€¼æ˜¯å¦æ»¡è¶³çˆ¬å¡é€Ÿç‡
                    before_value = value[i]
                    after_value = value[i + 1]
                    delta = after_value - before_value
                    abs_delta = abs(delta)
                    if abs_delta > ramp_rate:  # ä¸æ»¡è¶³æ—¶
                        if start_index is not None and (i + 1) > start_index:  # åä¸€ä¸ªç´¢å¼•è¶…è¿‡å…³æœºåŒºé—´æ—¶ä¸åšå¤„ç†ï¼Œç¬¬ä¸€ä¸ªåœæœºæ—¶é—´ç‚¹çš„å€¼æ”¾è¿‡ï¼Œå› ä¸ºè¦ä½œä¸ºä¿®æ­£çš„è¾¹ç•Œæ¡ä»¶
                            continue
                        if delta > 0:  # å¢åŠ å‡ºåŠ›æ—¶è¶…è¿‡çˆ¬å¡çº¦æŸ
                            value[i + 1] = before_value + ramp_rate
                        else:  # é™ä½å‡ºåŠ›æ—¶è¶…è¿‡çˆ¬å¡çº¦æŸ
                            value[i + 1] = before_value - ramp_rate
                        rul_df.at[i + 1, key] = value[i + 1]
                        if start_index is not None and (i+1) == start_index:  # ä¸åŒ…æ‹¬èµ·å§‹ç¬¬ä¸€ä¸ªç‚¹
                            continue
                        else:
                            new_turn_ramp_rate_df = insert_ramp_rate_unit(new_turn_ramp_rate_df, i+1, key, value[i+1])
                # æ ¹æ®åœæœºæ›²çº¿ç¬¬ä¸€ä¸ªæ—¶é—´çš„è´Ÿè·è¿›è¡Œçµæ´»æ›²çº¿è°ƒæ•´
                rul_df, flex_df = flexible_df_adjust(key, rul_df, flex_df)
        new_turn_ramp_rate_df = new_turn_ramp_rate_df.reset_index(drop=True)  # ç´¢å¼•é‡ç½®
        return new_turn_ramp_rate_df, flex_df

    # æ’å…¥æ•°æ®è¿›å»
    def insert_ramp_rate_unit(new_turn_ramp_rate_df, index, unit_name, value):
        exists = unit_name in new_turn_ramp_rate_df['unit'].values
        if exists:
            result = new_turn_ramp_rate_df[new_turn_ramp_rate_df['unit'] == unit_name]
            result_row = result.iloc[0]
            result_row['index'].append(index)
            result_row['fixed_load'].append(value)
        else:
            insert_df = pd.DataFrame(data={'unit': unit_name, 'index': [[index]], 'fixed_load': [[value]]})
            new_turn_ramp_rate_df = pd.concat([new_turn_ramp_rate_df, insert_df])
        return new_turn_ramp_rate_df

    # å¼€åœæœºçµæ´»æ›²çº¿åŠ¨æ€è°ƒæ•´
    def flexible_df_adjust(unit_name, rul_df, flex_df):
        rows = flex_df[flex_df['æœºç»„åç§°'] == unit_name]
        ramp_rate = get_unit_ramp_rate(ramp_rate_df, unit_name)
        if len(rows) > 0:
            row = rows.iloc[0]
            stop_curve = row['åœæœºæ›²çº¿']
            index_list = row['åŒºé—´ç´¢å¼•']
            if len(stop_curve) > 0:
                start_load = stop_curve[0]
                start_index = index_list[0]
                real_load = rul_df.at[start_index, unit_name]  # çœŸå®è´Ÿè·
                if start_load != real_load:  # ä¸ç›¸ç­‰æ—¶éœ€è¦è¿›è¡Œè°ƒæ•´
                    new_stop_curve = []
                    new_index_list = []
                    start_stop_row = start_stop_curve_df[start_stop_curve_df['æœºç»„åç§°'] == unit_name].iloc[0]
                    origin_stop_curve = start_stop_row['åœæœºæ›²çº¿']
                    origin_stop_curve = str_to_list(origin_stop_curve, None)
                    origin_start_load = origin_stop_curve[0]
                    while real_load > origin_start_load:
                        new_stop_curve.append(real_load)
                        new_index_list.append(start_index)
                        real_load = max(real_load - ramp_rate, origin_start_load)
                        if real_load == origin_start_load:
                            break
                        else:
                            start_index += 1
                    start_index = start_index + 1
                    for load in origin_stop_curve:
                        if start_index <= 95:
                            new_stop_curve.append(load)
                            new_index_list.append(start_index)
                            rul_df.at[start_index, unit_name] = load
                            start_index += 1
                        else:
                            break
                    row_index = flex_df.index[flex_df['æœºç»„åç§°'] == unit_name][0]
                    flex_df.at[row_index, 'åœæœºæ›²çº¿'] = new_stop_curve
                    flex_df.at[row_index, 'åŒºé—´ç´¢å¼•'] = new_index_list
        return rul_df, flex_df

    # åˆå¹¶
    def ramp_rate_integrate(trr_df, ntrr_df, rul_df, rr_df):
        if trr_df.empty:
            return ntrr_df
        else:
            for _, row in trr_df.iterrows():  # éå†ä¹‹å‰çš„æ•°æ®ï¼Œåˆ¤æ–­å½“å‰è¿­ä»£ä¸‹å‡ºæ¸…ï¼Œæ˜¯å¦ä¾ç„¶å­˜åœ¨å‰è¿­ä»£çš„çˆ¬å¡é™åˆ¶
                unit_name = row['unit']
                ramp_rate = get_unit_ramp_rate(rr_df, unit_name)
                index_list = row['index']
                fixed_load_list = row['fixed_load']
                new_index_list = []
                new_fixed_load_list = []
                for i in range(len(index_list)):
                    index = index_list[i]
                    load = fixed_load_list[i]
                    clearing_load = rul_df.at[index, unit_name]
                    before_clearing_load = rul_df.at[index - 1, unit_name]
                    delta = abs(clearing_load - before_clearing_load)
                    if delta == ramp_rate:  # å¦‚æœdeltaå’Œramp_rateä¸€æ ·åˆ™ä¿ç•™
                        new_index_list.append(index)
                        new_fixed_load_list.append(load)

                if len(new_index_list) > 0:  # æŠŠæ•°æ®åˆå¹¶åˆ°æ–°çš„ trr_df ä¸­
                    exists = unit_name in ntrr_df['unit'].values
                    if exists:  # å­˜åœ¨æ—¶æŒ‰indexé¡ºåºåˆå¹¶
                        result = ntrr_df[ntrr_df['unit'] == unit_name]
                        result_row = result.iloc[0]
                        result_index = result.index[0]
                        merged_index, merged_load = merge_lists(new_index_list, new_fixed_load_list, result_row['index'], result_row['fixed_load'])  # åˆå¹¶
                        ntrr_df.loc[result_index, 'index'] = merged_index
                        ntrr_df.loc[result_index, 'fixed_load'] = merged_load
                    else:  # ä¸å­˜åœ¨æ—¶æ’å…¥
                        new_row = pd.DataFrame(data={'unit': unit_name, 'index': [new_index_list], 'fixed_load': [new_fixed_load_list]})
                        ntrr_df = pd.concat([ntrr_df, new_row])
            return ntrr_df

    # å…¶ä½™è¾¹ç•Œæ¡ä»¶é™åˆ¶
    def boundary_condition(rul_df: pd.DataFrame, hfu_list, te_set, fl_list, q_df: pd.DataFrame,
                           sr_df: pd.DataFrame, rr_df: pd.DataFrame, trr_df):
        flag = True
        minfm_limit_unit_set= [set() for _ in range(96)]  # å› è°ƒé¢‘è¢«é™åˆ¶æœ€å°å‡ºåŠ›çš„æœºç»„åˆ—è¡¨
        maxfm_limit_unit_set = [set() for _ in range(96)]  # å› è°ƒé¢‘è¢«é™åˆ¶æœ€å¤§å‡ºåŠ›çš„æœºç»„åˆ—è¡¨
        sr_limit_unit_set = [set() for _ in range(96)]  # å› æ—‹å¤‡è¢«é™åˆ¶çš„æœºç»„åˆ—è¡¨
        for unit_name in rul_df.columns:
            unit_load = rul_df[unit_name].tolist()
            for idx, load in enumerate(unit_load):
                sr_load = get_unit_sr(sr_df, unit_name)  # æ—‹å¤‡å®¹é‡
                cap = get_unit_cap(q_df, unit_name)  # é¢å®šå®¹é‡
                hour = idx // 4
                if unit_name in hfu_list[hour]:  # å¦‚æœæ˜¯è°ƒé¢‘æœºç»„å°±è¦åˆ¤æ–­å…¶å‡ºåŠ›å€¼çš„åˆç†æ€§
                    max_limit = cap * max_cap - sr_load
                    min_limit = cap * min_cap
                    if load > max_limit:  # è¶…è¿‡æœ€å¤§
                        if sr_load != 0:  # å¦‚æœå­˜åœ¨æ—‹å¤‡
                            sr_limit_unit_set[idx].add(unit_name)
                        trr_df = remove_index(unit_name, idx, trr_df)
                        maxfm_limit_unit_set[idx].add(unit_name)
                        fl_list[idx] += max_limit
                        flag = False
                    if load < min_limit:  # ä½äºæœ€å°
                        index, _ = get_index(unit_name, idx, trr_df)
                        if index < 0:  # ä¸åœ¨çˆ¬å¡çº¦æŸé‡Œ
                            flag = False
                            ramp_rate = get_unit_ramp_rate(rr_df, unit_name)
                            if ramp_rate is not None:  # å­˜åœ¨çˆ¬å¡æ›²çº¿
                                if idx > 0:
                                    delta = rul_df.at[idx - 1, unit_name] + ramp_rate
                                    if delta >= min_limit:  # å¦‚æœæœºç»„å¯ä»¥é€šè¿‡çˆ¬å¡åˆ°æœ€å°å‡ºåŠ›
                                        fl_list[idx] += min_limit
                                        minfm_limit_unit_set[idx].add(unit_name)
                                    else:  # å¦‚æœä¸è¡Œï¼Œå°±åŠ å…¥åˆ°çˆ¬å¡çº¦æŸ
                                        trr_df = insert_ramp_rate_unit(trr_df, idx, unit_name, delta)
                                else:
                                    fl_list[idx] += min_limit
                                    minfm_limit_unit_set[idx].add(unit_name)
                            else:
                                fl_list[idx] += min_limit
                                minfm_limit_unit_set[idx].add(unit_name)
                else:
                    if unit_name not in te_set[idx]:  # ä¸æ˜¯è°ƒé¢‘ï¼Œå¹¶ä¸”ä¸æ˜¯è¯•éªŒæœºç»„ï¼Œåªè€ƒè™‘æ—‹å¤‡
                        max_limit = cap - sr_load
                        if load > max_limit:
                            trr_df = remove_index(unit_name, idx, trr_df)
                            sr_limit_unit_set[idx].add(unit_name)
                            fl_list[idx] += max_limit
                            flag = False
        return flag, minfm_limit_unit_set, maxfm_limit_unit_set, sr_limit_unit_set, fl_list, trr_df

    def get_index(unit_name, idx, trr_df):
        exists = unit_name in trr_df['unit'].values
        if exists:
            try:
                result = trr_df[trr_df['unit'] == unit_name]
                result_row = result.iloc[0]
                index_list = result_row['index']
                data_index = index_list.index(idx)
            except ValueError:
                data_index = -1
                result_row = None
            return data_index, result_row
        else:
            return -1, None

    # å»é™¤æŒ‡å®šçš„æ•°æ®
    def remove_index(unit_name, idx, trr_df):
        data_index, result_row = get_index(unit_name, idx, trr_df)
        if data_index > 0:
            index_list = result_row['index']
            fixed_load_list = result_row['fixed_load']
            data_index = index_list.index(idx)
            index_list.pop(data_index)  # ç§»é™¤åˆ—è¡¨ä¸­æŒ‡å®šç´¢å¼•çš„å…ƒç´ 
            fixed_load_list.pop(data_index)
        return trr_df

    def getPeakValleyConfig(pvd: pd.DataFrame, date: str):
        month = date.split('-')[1]
        data_map = {}
        if peak_valley_df is not None:
            for _, row in pvd.iterrows():
                month_list = row['æœˆä»½'].split(',')
                if month in month_list:
                    data_map[0] = row['å°–å³°'].split(',') if row['å°–å³°'] is not None else None
                    data_map[1] = row['é«˜å³°'].split(',') if row['é«˜å³°'] is not None else None
                    data_map[2] = row['å¹³æ®µ'].split(',') if row['å¹³æ®µ'] is not None else None
                    data_map[3] = row['ä½è°·'].split(',') if row['ä½è°·'] is not None else None
                    return data_map
        return None

    def getPeakValleyPrice(pvd: pd.DataFrame, ppd: pd.DataFrame, sd: pd.DataFrame, date: str):
        data_map = getPeakValleyConfig(pvd, date)
        price_list = ppd['pred_price'].tolist()
        space_list = sd['load'].tolist()
        result_list = []
        if data_map is not None:
            for i in range(4):
                hour_list = data_map[i]
                if hour_list is not None:
                    price_total = 0
                    space_total = 0
                    for hour in hour_list:
                        start_index = get_time_index(hour)
                        if start_index == 95:
                            start_index = -1
                        for j in range(4):
                            price_total += price_list[start_index + 1 + j] * space_list[start_index + 1 + j]
                            space_total += space_list[start_index + 1 + j]
                    result_list.append(round(price_total / space_total, 4))
                else:
                    result_list.append(0)
        return result_list

    @st.cache_data
    def clearing_out(df, pl, fm_quotation, spinning_reserve, startup_shutdown):
        # å¼€åœæœºæ•°æ®æ•´ç†
        unit_start_stop_df = pd.DataFrame()
        for _, value in startup_shutdown.items():
            unit_start_stop_df = pd.concat([unit_start_stop_df, value])
        unit_start_stop_df.reset_index(inplace=True)
        unit_start_stop_df.rename(columns={'index': 'æœºç»„åç§°'}, inplace=True)

        # 24æ—¶æ®µè°ƒé¢‘å®¹é‡
        result = pl[pl['ä¿¡æ¯æŠ«éœ²åç§°'] == 'æ—¥å‰è°ƒé¢‘éœ€æ±‚']
        fm_part = result.iloc[0].tolist()
        fm_part = fm_part[2:26]
        fm_list = [float(x) for x in fm_part]

        # æ•°æ®å‡†å¤‡
        time_shut_set, time_exp_set, time_exp_load_list, flexible_df = time_shut_exp_unit_and_load(unit_start_stop_df, start_stop_curve_df)  # æ¯15minçš„å…³æœºæœºç»„ï¼Œè¯•éªŒæœºç»„ï¼Œè¯•éªŒè´Ÿè·çš„list
        time_shut_exp_set = [set1.union(set2) for set1, set2 in zip(time_shut_set, time_exp_set)]  # å…³æœºå’Œè¯•éªŒæœºliståˆå¹¶
        hour_fm_unit_list = get_hour_fm_unit(fm_quotation, fm_list, time_shut_exp_set)  # æ¯å°æ—¶å‚ä¸è°ƒé¢‘çš„æœºç»„

        load_pred_df = thermal_load(pl)
        space_list = load_pred_df['load'].tolist()  # ç«ç”µç©ºé—´
        remove_unit_set = time_shut_exp_set  # è¦å»é™¤çš„æœºç»„
        fixed_load_list = time_exp_load_list  # å›ºå®šè´Ÿè·

        turn_ramp_rate_df = pd.DataFrame(columns=['unit', 'index', 'fixed_load'])  # æ¯è¿­ä»£ä¸€æ¬¡å°±ä¼šæœ‰ä¸€ä¸ªæ–°çš„
        min_fm_limit_unit_set = [set() for _ in range(96)]  # å› è°ƒé¢‘è¢«é™åˆ¶æœ€å°å‡ºåŠ›çš„æœºç»„åˆ—è¡¨
        max_fm_limit_unit_set = [set() for _ in range(96)]  # å› è°ƒé¢‘è¢«é™åˆ¶æœ€å¤§å‡ºåŠ›çš„æœºç»„åˆ—è¡¨
        sr_limit_unit_set = [set() for _ in range(96)]  # å› æ—‹å¤‡è¢«é™åˆ¶çš„æœºç»„åˆ—è¡¨
        clearing_flag = False
        result_price_pred_df = pd.DataFrame()
        result_unit_load_df = pd.DataFrame()
        times = 0
        logger.info('---------------------------------------------')
        logger.info(f'start clearing')

        # å¾ªç¯å‡ºæ¸…ç›´åˆ°æ»¡è¶³è¾¹ç•Œæ¡ä»¶
        while not clearing_flag:  # ä¸æ»¡è¶³å‡ºæ¸…çš„è¾¹ç•Œæ¡ä»¶å°±ç»§ç»­å¾ªç¯
            times += 1
            logger.info(f'clearing times: {times}')
            result_price_pred_df = pd.DataFrame()
            result_unit_load_df = pd.DataFrame()
            now_space_list = copy.deepcopy(space_list)

            # å›ºå®šè´Ÿè·è°ƒæ•´
            flexible_load_list = load_list_combine_flexible_df(fixed_load_list, flexible_df, turn_ramp_rate_df)  # å’Œå¼€åœæœºçµæ´»æ›²çº¿dfä»¥åŠçˆ¬å¡dfåˆå¹¶
            # ç§»é™¤çš„æœºç»„è°ƒæ•´
            turn_remove_unit_set = remove_set_combine_ramp_rate(remove_unit_set, turn_ramp_rate_df)

            period_list_map = get_diff_sc_period(turn_remove_unit_set)  # é˜¶æ®µä¾›ç»™æ›²çº¿
            for period in period_list_map:
                period_range = None
                all_remove_unit_set = None
                for key, value in period.items():  # å­—å…¸é‡Œåªæœ‰ä¸€ç»„æ•°æ®
                    period_range = key
                    all_remove_unit_set = value
                start_period = int(period_range.split('-')[0])
                end_period = int(period_range.split('-')[1])
                for i in range(start_period, end_period + 1):  # éå†è´Ÿè·
                    now_space_list[i] = space_list[i] - flexible_load_list[i]

                # ä¸»ç¨‹åºéƒ¨åˆ†
                data_df, station_df = data_process(df, all_remove_unit_set)  # æŠ¥ä»·è¡¨æ•°æ®å¤„ç†ï¼Œä»ä¸­å»é™¤æ‰éƒ¨åˆ†æœºç»„
                supply_df, station_df = supply_curve(data_df, station_df)  # ä¾›ç»™æ›²çº¿
                price_pred_df = price_pred(now_space_list, supply_df)  # ç”µä»·é¢„æµ‹
                unit_load_df = load_pred(data_df, station_df, price_pred_df)  # å„æœºç»„å‡ºåŠ›å€¼é¢„æµ‹

                # æ•°æ®åˆå¹¶
                result_price_pred_df = pd.concat([result_price_pred_df, price_pred_df.iloc[start_period: end_period + 1]], ignore_index=True, sort=False)
                result_unit_load_df = pd.concat([result_unit_load_df, unit_load_df.iloc[start_period: end_period + 1]], ignore_index=True, sort=False)

            # æœºç»„å‡ºæ¸…æ•°æ®æ•´åˆ
            result_unit_load_df = result_unit_load_df_process(result_unit_load_df, unit_start_stop_df, df,
                                                              spinning_reserve, flexible_df,
                                                              time_shut_set, time_exp_set,
                                                              min_fm_limit_unit_set, max_fm_limit_unit_set,
                                                              sr_limit_unit_set, turn_ramp_rate_df)

            # çˆ¬å¡é€Ÿç‡æ¡ä»¶é™åˆ¶ï¼Œè·å–æ–°ä¸€è½®è¿­ä»£çš„ turn_ramp_rateå’Œ flexible_df
            new_turn_ramp_rate_df, flexible_df = ramp_rate_boundary(result_unit_load_df, ramp_rate_df, flexible_df)
            # çˆ¬å¡é€Ÿç‡æ¡ä»¶é™åˆ¶çš„æ•´åˆ
            turn_ramp_rate_df = ramp_rate_integrate(turn_ramp_rate_df, new_turn_ramp_rate_df, result_unit_load_df, ramp_rate_df)

            # å…¶ä»–è¾¹ç•Œæ¡ä»¶åˆ¤æ–­
            # çˆ¬å¡å›ºå®šè´Ÿè·è½¬çµæ´»
            clearing_flag, new_minfm_limit_unit_set, new_maxfm_limit_unit_set, new_sr_limit_unit_set, new_fixed_load_list, turn_ramp_rate_df = \
                boundary_condition(result_unit_load_df, hour_fm_unit_list, time_exp_set, fixed_load_list, df, spinning_reserve, ramp_rate_df, turn_ramp_rate_df)

            # å›ºå®šè´Ÿè·é‡ç½®
            fixed_load_list = new_fixed_load_list

            min_fm_limit_unit_set = [set1.union(set2) for set1, set2 in
                                      zip(min_fm_limit_unit_set, new_minfm_limit_unit_set)]  # æ›´æ–°æ•°æ®
            max_fm_limit_unit_set = [set1.union(set2) for set1, set2 in
                                      zip(max_fm_limit_unit_set, new_maxfm_limit_unit_set)]
            sr_limit_unit_set = [set1.union(set2) for set1, set2 in zip(sr_limit_unit_set, new_sr_limit_unit_set)]
            remove_unit_set = [set1.union(set2, set3, set4) for set1, set2, set3, set4 in
                                zip(remove_unit_set, min_fm_limit_unit_set, max_fm_limit_unit_set,
                                    sr_limit_unit_set)]

        logger.info(f'clearing end')
        logger.info('---------------------------------------------')
        return result_price_pred_df, result_unit_load_df

    # å‡ºæ¸…ç»“æœå¤„ç†
    result_price_pred_df, result_unit_load_df = clearing_out(df, pl, fm_quotation, spinning_reserve, startup_shutdown)
    price_pred_df = result_price_pred_df
    station_load_df = result_unit_load_df

    st.markdown('ç”µä»·æ•°æ®')
    q1, q2, q3 = st.tabs(['æ›²çº¿', 'æ•°æ®', 'å³°å¹³è°·ç”µä»·'])
    with q1:
        date = pl['æ‰€å±æ—¥æœŸ'].values[0]
        st.line_chart(price_pred_df['pred_price'].tolist())
    with q2:
        price_df = pd.DataFrame()
        for i in range(12):
            price_df['æ—¶é—´' + str(i + 1)] = time_list[8 * i: 8 * i + 8]
            price_df['ä»·æ ¼' + str(i + 1)] = price_pred_df['pred_price'].tolist()[8 * i:8 * i + 8]
        st.write(price_df)
    with q3:
        space_df = thermal_load(pl)
        price_avg_list = getPeakValleyPrice(peak_valley_df, price_pred_df, space_df, date)
        price_avg_df = pd.DataFrame(columns=['å°–å³°å¹³å‡ç”µä»·', 'é«˜å³°å¹³å‡ç”µä»·', 'å¹³æ®µå¹³å‡ç”µä»·', 'ä½è°·å¹³å‡ç”µä»·'])
        new_row_series = pd.Series(price_avg_list, index=price_avg_df.columns)
        price_avg_df = pd.concat([price_avg_df, new_row_series.to_frame().T], ignore_index=True)
        st.table(price_avg_df)

    unit_df = st.session_state['æœºç»„å…³ç³»è¡¨']
    # æ±‚å…¨çœå„ä¸ªé›†å›¢çš„ä¿¡æ¯
    st.markdown('å„é›†å›¢å‡ºæ¸…ç»“æœ')
    df1 = pd.DataFrame(index=["å…¨çœ", "èµ£èƒ½", "åèƒ½", "å›½å®¶èƒ½æº", "å›½å®¶ç”µæŠ•", 'å¤§å”'],
                       columns=['è£…æœºå®¹é‡', 'å¼€æœºå®¹é‡', 'å‘ç”µé‡', 'æœ€é«˜ä»·æ ¼', 'æœ€ä½ä»·æ ¼', 'å¹³å‡ä»·æ ¼', 'è´Ÿè·ç‡',
                                'å‘ç”µè¿›åº¦'])
    for ji_tuan in group_lists:
        unit_list = unit_df.loc[unit_df['é›†å›¢'] == ji_tuan, 'æœºç»„åç§°'].tolist()
        start_unit = list(set(unit_list).intersection(set(station_load_df.columns.tolist())))
        df1.loc[ji_tuan, 'è£…æœºå®¹é‡'] = sum(
            df.loc[df['æœºç»„åç§°'].isin(unit_list), 'æœºç»„å®¹é‡(MW)'].astype(float).tolist())
        df1.loc[ji_tuan, 'å¼€æœºå®¹é‡'] = sum(
            df.loc[df['æœºç»„åç§°'].isin(start_unit), 'æœºç»„å®¹é‡(MW)'].astype(float).tolist())
        df1.loc[ji_tuan, 'å‘ç”µé‡'] = sum(station_load_df.loc[:, start_unit].sum(axis=1).tolist()) / 4
        all_price = 0
        for unit in start_unit:
            all_price += sum(station_load_df[unit] * price_pred_df['pred_price'])
        df1.loc[ji_tuan, 'å¹³å‡ä»·æ ¼'] = all_price / df1.loc[ji_tuan, 'å‘ç”µé‡'] / 4
        df1.loc[ji_tuan, 'è´Ÿè·ç‡'] = df1.loc[ji_tuan, 'å‘ç”µé‡'] / df1.loc[ji_tuan, 'å¼€æœºå®¹é‡'] / 24
    df1.loc['å…¨çœ', ['è£…æœºå®¹é‡', 'å¼€æœºå®¹é‡', 'å‘ç”µé‡']] = sum(
        df1.loc['èµ£èƒ½':, ['è£…æœºå®¹é‡', 'å¼€æœºå®¹é‡', 'å‘ç”µé‡']].values)
    df1.loc['å…¨çœ', 'å¹³å‡ä»·æ ¼'] = np.mean(df1.loc['èµ£èƒ½':, 'å¹³å‡ä»·æ ¼'].values)
    df1.loc['å…¨çœ', 'è´Ÿè·ç‡'] = df1.loc['å…¨çœ', 'å‘ç”µé‡'] / df1.loc['å…¨çœ', 'å¼€æœºå®¹é‡'] / 24
    df1.loc['å…¨çœ', 'å‘ç”µè¿›åº¦'] = 1
    df1['æœ€é«˜ä»·æ ¼'] = price_pred_df['pred_price'].max()
    df1['æœ€ä½ä»·æ ¼'] = price_pred_df['pred_price'].min()
    for ji_tuan in ["èµ£èƒ½", "åèƒ½", "å›½å®¶èƒ½æº", "å›½å®¶ç”µæŠ•", 'å¤§å”']:
        df1.loc[ji_tuan, 'å‘ç”µè¿›åº¦'] = df1.loc[ji_tuan, 'å‘ç”µé‡'] / df1.loc[ji_tuan, 'è£…æœºå®¹é‡'] / (
                df1.loc['å…¨çœ', 'å‘ç”µé‡'] / df1.loc['å…¨çœ', 'è£…æœºå®¹é‡'])

    # æ±‚å„ä¸ªæœºç»„çš„ä¿¡æ¯
    tab1, tab2, tab3, tab4, tab5 = st.tabs(group_lists)
    jt_map = {tab1: "èµ£èƒ½", tab2: "åèƒ½", tab3: "å›½å®¶èƒ½æº", tab4: "å›½å®¶ç”µæŠ•", tab5: 'å¤§å”'}
    for ji_tuan in group_lists:
        i = next(key for key, value in jt_map.items() if value == ji_tuan)  # è·å–å½“å‰é›†å›¢çš„keyå€¼ï¼Œä¹Ÿå°±æ˜¯tab
        unit_list = []
        origin_unit_list = unit_df.loc[unit_df['é›†å›¢'] == ji_tuan, 'æœºç»„åç§°'].tolist()
        for unit in origin_unit_list:
            unit_cap = df.loc[df['æœºç»„åç§°'] == unit, 'æœºç»„å®¹é‡(MW)'].values  # è£…æœºå®¹é‡ä¸ºæœºç»„å®¹é‡
            if unit_cap.size == 0 or unit_cap is None:
                continue
            else:
                unit_list.append(unit)
        start_unit = list(set(unit_list).intersection(set(station_load_df.columns.tolist())))  # æ¯ä¸ªé›†å›¢çš„å¼€æœºæœºç»„
        df2 = pd.DataFrame(index=[ji_tuan] + unit_list,
                           columns=['è£…æœºå®¹é‡', 'å¼€æœºå®¹é‡', 'å‘ç”µé‡', 'æœ€é«˜ä»·æ ¼', 'æœ€ä½ä»·æ ¼', 'å¹³å‡ä»·æ ¼', 'è´Ÿè·ç‡',
                                    'å‘ç”µè¿›åº¦'])  # é›†å›¢æ€»çš„å’Œå„æœºç»„çš„æ•°æ®
        df2.loc[ji_tuan] = df1.loc[ji_tuan]
        for unit in unit_list:
            unit_cap = df.loc[df['æœºç»„åç§°'] == unit, 'æœºç»„å®¹é‡(MW)'].values  # è£…æœºå®¹é‡ä¸ºæœºç»„å®¹é‡
            df2.loc[unit, 'è£…æœºå®¹é‡'] = unit_cap[0]
            if unit in start_unit:
                df2.loc[unit, 'å¼€æœºå®¹é‡'] = df.loc[df['æœºç»„åç§°'] == unit, 'æœºç»„å®¹é‡(MW)'].values  # å¼€æœºå®¹é‡ä¸ºå¼€æœºæœºç»„å®¹é‡ä¹‹å’Œ
                df2.loc[unit, 'å‘ç”µé‡'] = station_load_df.loc[:, unit].sum() / 4
                df2.loc[unit, 'å¹³å‡ä»·æ ¼'] = sum(
                    station_load_df[unit] * price_pred_df['pred_price']) / station_load_df.loc[:, unit].sum()
                df2.loc[unit, 'è´Ÿè·ç‡'] = df2.loc[unit, 'å‘ç”µé‡'] / float(df2.loc[unit, 'å¼€æœºå®¹é‡']) / 24
            else:
                df2.loc[unit, ['å¼€æœºå®¹é‡', 'å‘ç”µé‡', 'å¹³å‡ä»·æ ¼', 'è´Ÿè·ç‡', 'å‘ç”µè¿›åº¦']] = 0
        df2['æœ€é«˜ä»·æ ¼'] = df2['æœ€é«˜ä»·æ ¼'][0]
        df2['æœ€ä½ä»·æ ¼'] = df2['æœ€ä½ä»·æ ¼'][0]
        for unit in start_unit:
            df2.loc[unit, 'å‘ç”µè¿›åº¦'] = df2.loc[unit, 'å‘ç”µé‡'] / float(df2.loc[unit, 'è£…æœºå®¹é‡']) / (
                    df1.loc['å…¨çœ', 'å‘ç”µé‡'] / df1.loc['å…¨çœ', 'è£…æœºå®¹é‡'])
        df2[['å‘ç”µé‡', 'æœ€é«˜ä»·æ ¼', 'æœ€ä½ä»·æ ¼', 'å¹³å‡ä»·æ ¼']] = df2[['å‘ç”µé‡', 'æœ€é«˜ä»·æ ¼', 'æœ€ä½ä»·æ ¼', 'å¹³å‡ä»·æ ¼']].round(
            2)
        df2[['è´Ÿè·ç‡', 'å‘ç”µè¿›åº¦']] = df2[['è´Ÿè·ç‡', 'å‘ç”µè¿›åº¦']].apply(lambda x: x.map('{:.2%}'.format))
        with i:
            df2['è£…æœºå®¹é‡'] = df2['è£…æœºå®¹é‡'].astype(float)
            df2['å¼€æœºå®¹é‡'] = df2['å¼€æœºå®¹é‡'].astype(float)
            st.write(df2)

    st.markdown('å…¨çœå‡ºæ¸…ç»Ÿè®¡')
    df1[['å‘ç”µé‡', 'æœ€é«˜ä»·æ ¼', 'æœ€ä½ä»·æ ¼', 'å¹³å‡ä»·æ ¼']] = df1[['å‘ç”µé‡', 'æœ€é«˜ä»·æ ¼', 'æœ€ä½ä»·æ ¼', 'å¹³å‡ä»·æ ¼']].round(2)
    df1[['è´Ÿè·ç‡', 'å‘ç”µè¿›åº¦']] = df1[['è´Ÿè·ç‡', 'å‘ç”µè¿›åº¦']].apply(lambda x: x.map('{:.2%}'.format))
    st.write(df1)

    st.markdown('å…¨çœæœºç»„å‡ºæ¸…è¡¨')
    c1, c2 = st.tabs(['æ•°æ®', 'æ›²çº¿'])
    time_list[-1] = '24:00'
    station_load_df['time'] = time_list
    station_load_df.set_index('time', inplace=True)
    with c1:
        st.write(station_load_df)
    with c2:
        stations = station_load_df.columns
        options = st.multiselect('é€‰æ‹©æœºç»„', stations)
        line_df = station_load_df[options]
        st.line_chart(line_df)
